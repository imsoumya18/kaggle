{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-15T08:11:52.547317Z",
     "start_time": "2024-04-15T08:11:45.980297Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:11:52.864029Z",
     "start_time": "2024-04-15T08:11:52.557148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(\"spaceship-titanic/train.csv\")\n",
    "test = pd.read_csv(\"spaceship-titanic/test.csv\")\n",
    "test_ids = test['PassengerId']"
   ],
   "id": "bc462ac9caa9c14c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:11:53.036123Z",
     "start_time": "2024-04-15T08:11:52.866770Z"
    }
   },
   "cell_type": "code",
   "source": "data",
   "id": "dbb7c0a763be69a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "0        0001_01     Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n",
       "1        0002_01      Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n",
       "2        0003_01     Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n",
       "3        0003_02     Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n",
       "4        0004_01      Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n",
       "...          ...        ...       ...       ...            ...   ...    ...   \n",
       "8688     9276_01     Europa     False    A/98/P    55 Cancri e  41.0   True   \n",
       "8689     9278_01      Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n",
       "8690     9279_01      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n",
       "8691     9280_01     Europa     False   E/608/S    55 Cancri e  32.0  False   \n",
       "8692     9280_02     Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0             0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1           109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2            43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3             0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4           303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "...           ...        ...           ...     ...     ...                ...   \n",
       "8688          0.0     6819.0           0.0  1643.0    74.0  Gravior Noxnuther   \n",
       "8689          0.0        0.0           0.0     0.0     0.0    Kurta Mondalley   \n",
       "8690          0.0        0.0        1872.0     1.0     0.0       Fayey Connon   \n",
       "8691          0.0     1049.0           0.0   353.0  3235.0   Celeon Hontichre   \n",
       "8692        126.0     4688.0           0.0     0.0    12.0   Propsh Hontichre   \n",
       "\n",
       "      Transported  \n",
       "0           False  \n",
       "1            True  \n",
       "2           False  \n",
       "3           False  \n",
       "4            True  \n",
       "...           ...  \n",
       "8688        False  \n",
       "8689        False  \n",
       "8690         True  \n",
       "8691        False  \n",
       "8692         True  \n",
       "\n",
       "[8693 rows x 14 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/98/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Gravior Noxnuther</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1499/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kurta Mondalley</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/1500/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fayey Connon</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>Celeon Hontichre</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Propsh Hontichre</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows × 14 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:11:53.208776Z",
     "start_time": "2024-04-15T08:11:53.040450Z"
    }
   },
   "cell_type": "code",
   "source": "data.info()",
   "id": "fc3ffb1efd83d5dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   8693 non-null   object \n",
      " 1   HomePlanet    8492 non-null   object \n",
      " 2   CryoSleep     8476 non-null   object \n",
      " 3   Cabin         8494 non-null   object \n",
      " 4   Destination   8511 non-null   object \n",
      " 5   Age           8514 non-null   float64\n",
      " 6   VIP           8490 non-null   object \n",
      " 7   RoomService   8512 non-null   float64\n",
      " 8   FoodCourt     8510 non-null   float64\n",
      " 9   ShoppingMall  8485 non-null   float64\n",
      " 10  Spa           8510 non-null   float64\n",
      " 11  VRDeck        8505 non-null   float64\n",
      " 12  Name          8493 non-null   object \n",
      " 13  Transported   8693 non-null   bool   \n",
      "dtypes: bool(1), float64(6), object(7)\n",
      "memory usage: 891.5+ KB\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:11:53.216856Z",
     "start_time": "2024-04-15T08:11:53.210604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean(df):\n",
    "    df['Group'] = df.apply(lambda row: row['PassengerId'].split('_')[0], axis=1)\n",
    "\n",
    "    drops = ['PassengerId', 'Name']\n",
    "\n",
    "    df.drop(drops, axis=1, inplace=True)\n",
    "\n",
    "    df['Cabin'] = str(df['Cabin'])\n",
    "\n",
    "    return df"
   ],
   "id": "a5761070029371a4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:11:53.610703Z",
     "start_time": "2024-04-15T08:11:53.221744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = clean(data)\n",
    "test = clean(test)"
   ],
   "id": "c11037835ad9008a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:11:58.277924Z",
     "start_time": "2024-04-15T08:11:53.612282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "labels = ['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP']\n",
    "\n",
    "for col in labels:\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    label_encoder.fit(pd.concat([data[col], test[col]]))\n",
    "    data[col] = label_encoder.transform(data[col])\n",
    "    test[col] = label_encoder.transform(test[col])"
   ],
   "id": "9b618afd3951e8e4",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:11:58.320752Z",
     "start_time": "2024-04-15T08:11:58.279964Z"
    }
   },
   "cell_type": "code",
   "source": "data",
   "id": "5ed13cb4f5150015",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      HomePlanet  CryoSleep  Cabin  Destination   Age  VIP  RoomService  \\\n",
       "0              1          0      0            2  39.0    0          0.0   \n",
       "1              0          0      0            2  24.0    0        109.0   \n",
       "2              1          0      0            2  58.0    1         43.0   \n",
       "3              1          0      0            2  33.0    0          0.0   \n",
       "4              0          0      0            2  16.0    0        303.0   \n",
       "...          ...        ...    ...          ...   ...  ...          ...   \n",
       "8688           1          0      0            0  41.0    1          0.0   \n",
       "8689           0          1      0            1  18.0    0          0.0   \n",
       "8690           0          0      0            2  26.0    0          0.0   \n",
       "8691           1          0      0            0  32.0    0          0.0   \n",
       "8692           1          0      0            2  44.0    0        126.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall     Spa  VRDeck  Transported Group  \n",
       "0           0.0           0.0     0.0     0.0        False  0001  \n",
       "1           9.0          25.0   549.0    44.0         True  0002  \n",
       "2        3576.0           0.0  6715.0    49.0        False  0003  \n",
       "3        1283.0         371.0  3329.0   193.0        False  0003  \n",
       "4          70.0         151.0   565.0     2.0         True  0004  \n",
       "...         ...           ...     ...     ...          ...   ...  \n",
       "8688     6819.0           0.0  1643.0    74.0        False  9276  \n",
       "8689        0.0           0.0     0.0     0.0        False  9278  \n",
       "8690        0.0        1872.0     1.0     0.0         True  9279  \n",
       "8691     1049.0           0.0   353.0  3235.0        False  9280  \n",
       "8692     4688.0           0.0     0.0    12.0         True  9280  \n",
       "\n",
       "[8693 rows x 13 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>False</td>\n",
       "      <td>9276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>9278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>9279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>False</td>\n",
       "      <td>9280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>True</td>\n",
       "      <td>9280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows × 13 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:11:58.469309Z",
     "start_time": "2024-04-15T08:11:58.325623Z"
    }
   },
   "cell_type": "code",
   "source": "test",
   "id": "b0a884779571182",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      HomePlanet  CryoSleep  Cabin  Destination   Age  VIP  RoomService  \\\n",
       "0              0          1      1            2  27.0    0          0.0   \n",
       "1              0          0      1            2  19.0    0          0.0   \n",
       "2              1          1      1            0  31.0    0          0.0   \n",
       "3              1          0      1            2  38.0    0          0.0   \n",
       "4              0          0      1            2  20.0    0         10.0   \n",
       "...          ...        ...    ...          ...   ...  ...          ...   \n",
       "4272           0          1      1            2  34.0    0          0.0   \n",
       "4273           0          0      1            2  42.0    0          0.0   \n",
       "4274           2          1      1            0   NaN    0          0.0   \n",
       "4275           1          0      1            3   NaN    0          0.0   \n",
       "4276           0          1      1            1  43.0    0          0.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall     Spa  VRDeck Group  \n",
       "0           0.0           0.0     0.0     0.0  0013  \n",
       "1           9.0           0.0  2823.0     0.0  0018  \n",
       "2           0.0           0.0     0.0     0.0  0019  \n",
       "3        6652.0           0.0   181.0   585.0  0021  \n",
       "4           0.0         635.0     0.0     0.0  0023  \n",
       "...         ...           ...     ...     ...   ...  \n",
       "4272        0.0           0.0     0.0     0.0  9266  \n",
       "4273      847.0          17.0    10.0   144.0  9269  \n",
       "4274        0.0           0.0     0.0     0.0  9271  \n",
       "4275     2680.0           0.0     0.0   523.0  9273  \n",
       "4276        0.0           0.0     0.0     0.0  9277  \n",
       "\n",
       "[4277 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>9269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>9273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:11:58.553246Z",
     "start_time": "2024-04-15T08:11:58.474639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_dataset(dataset, test_ratio=0.20):\n",
    "    test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "    return dataset[~test_indices], dataset[test_indices]\n",
    "\n",
    "\n",
    "train_ds_pd, test_ds_pd = split_dataset(data)\n",
    "print(\"{} examples in training, {} examples for testing.\".format(len(train_ds_pd), len(test_ds_pd)))"
   ],
   "id": "e7f263da4db6e2d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6952 examples in training, 1741 examples for testing.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:13:18.498096Z",
     "start_time": "2024-04-15T08:11:58.564658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label='Transported')\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label='Transported')"
   ],
   "id": "ea728d5c4c8a21dc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 13:42:18.382018: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-15 13:42:39.833389: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-04-15 13:43:13.703062: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-15 13:43:13.929622: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:13:18.549390Z",
     "start_time": "2024-04-15T08:13:18.537438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For whole dataset\n",
    "# import tensorflow_decision_forests as tfdf\n",
    "# \n",
    "# train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(data, label='Transported')"
   ],
   "id": "4da173e95ee99249",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:18:13.690940Z",
     "start_time": "2024-04-15T08:13:18.558307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = tfdf.keras.RandomForestModel(verbose=2)\n",
    "\n",
    "model.fit(train_ds)"
   ],
   "id": "8f37fbd7b1595388",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 8 thread(s) for training\n",
      "Use /tmp/tmp79khj61v as temporary training directory\n",
      "Reading training dataset...\n",
      "Training tensor examples:\n",
      "Features: {'HomePlanet': <tf.Tensor 'data:0' shape=(None,) dtype=int64>, 'CryoSleep': <tf.Tensor 'data_1:0' shape=(None,) dtype=int64>, 'Cabin': <tf.Tensor 'data_2:0' shape=(None,) dtype=int64>, 'Destination': <tf.Tensor 'data_3:0' shape=(None,) dtype=int64>, 'Age': <tf.Tensor 'data_4:0' shape=(None,) dtype=float64>, 'VIP': <tf.Tensor 'data_5:0' shape=(None,) dtype=int64>, 'RoomService': <tf.Tensor 'data_6:0' shape=(None,) dtype=float64>, 'FoodCourt': <tf.Tensor 'data_7:0' shape=(None,) dtype=float64>, 'ShoppingMall': <tf.Tensor 'data_8:0' shape=(None,) dtype=float64>, 'Spa': <tf.Tensor 'data_9:0' shape=(None,) dtype=float64>, 'VRDeck': <tf.Tensor 'data_10:0' shape=(None,) dtype=float64>, 'Group': <tf.Tensor 'data_11:0' shape=(None,) dtype=string>}\n",
      "Label: Tensor(\"data_12:0\", shape=(None,), dtype=bool)\n",
      "Weights: None\n",
      "Normalized tensor features:\n",
      " {'HomePlanet': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'CryoSleep': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'Cabin': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'Destination': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'Age': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>), 'VIP': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_5:0' shape=(None,) dtype=float32>), 'RoomService': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_6:0' shape=(None,) dtype=float32>), 'FoodCourt': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_7:0' shape=(None,) dtype=float32>), 'ShoppingMall': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_8:0' shape=(None,) dtype=float32>), 'Spa': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_9:0' shape=(None,) dtype=float32>), 'VRDeck': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_10:0' shape=(None,) dtype=float32>), 'Group': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_11:0' shape=(None,) dtype=string>)}\n",
      "Training dataset read in 0:02:27.285750. Found 6952 examples.\n",
      "Training model...\n",
      "Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training gets stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-04-15 13:45:59.5817 IST kernel.cc:771] Start Yggdrasil model training\n",
      "[INFO 24-04-15 13:45:59.6078 IST kernel.cc:772] Collect training examples\n",
      "[INFO 24-04-15 13:45:59.6631 IST kernel.cc:785] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "[INFO 24-04-15 13:46:00.0439 IST kernel.cc:391] Number of batches: 7\n",
      "[INFO 24-04-15 13:46:00.0439 IST kernel.cc:392] Number of examples: 6952\n",
      "[INFO 24-04-15 13:46:00.0862 IST data_spec_inference.cc:305] 5128 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Group (83 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "[INFO 24-04-15 13:46:00.0899 IST kernel.cc:792] Training dataset:\n",
      "Number of records: 6952\n",
      "Number of columns: 13\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 11 (84.6154%)\n",
      "\tCATEGORICAL: 2 (15.3846%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 11 (84.6154%)\n",
      "\t0: \"Age\" NUMERICAL num-nas:148 (2.12888%) mean:28.7716 min:0 max:79 sd:14.5002\n",
      "\t1: \"Cabin\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t2: \"CryoSleep\" NUMERICAL mean:0.402474 min:0 max:2 sd:0.54142\n",
      "\t3: \"Destination\" NUMERICAL mean:1.51251 min:0 max:3 sd:0.84082\n",
      "\t4: \"FoodCourt\" NUMERICAL num-nas:151 (2.17204%) mean:463.467 min:0 max:29813 sd:1643.53\n",
      "\t6: \"HomePlanet\" NUMERICAL mean:0.718067 min:0 max:3 sd:0.866143\n",
      "\t7: \"RoomService\" NUMERICAL num-nas:144 (2.07135%) mean:220.776 min:0 max:14327 sd:660.169\n",
      "\t8: \"ShoppingMall\" NUMERICAL num-nas:165 (2.37342%) mean:169.836 min:0 max:23492 sd:598.491\n",
      "\t9: \"Spa\" NUMERICAL num-nas:153 (2.20081%) mean:311.063 min:0 max:22408 sd:1149.1\n",
      "\t10: \"VIP\" NUMERICAL mean:0.0704833 min:0 max:2 sd:0.335702\n",
      "\t11: \"VRDeck\" NUMERICAL num-nas:152 (2.18642%) mean:312.163 min:0 max:24133 sd:1175.7\n",
      "\n",
      "CATEGORICAL: 2 (15.3846%)\n",
      "\t5: \"Group\" CATEGORICAL has-dict vocab-size:84 num-oods:6470 (93.0667%) most-frequent:\"<OOD>\" 6470 (93.0667%)\n",
      "\t12: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO 24-04-15 13:46:00.0901 IST kernel.cc:808] Configure learner\n",
      "[INFO 24-04-15 13:46:00.7239 IST kernel.cc:822] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Age$\"\n",
      "features: \"^Cabin$\"\n",
      "features: \"^CryoSleep$\"\n",
      "features: \"^Destination$\"\n",
      "features: \"^FoodCourt$\"\n",
      "features: \"^Group$\"\n",
      "features: \"^HomePlanet$\"\n",
      "features: \"^RoomService$\"\n",
      "features: \"^ShoppingMall$\"\n",
      "features: \"^Spa$\"\n",
      "features: \"^VIP$\"\n",
      "features: \"^VRDeck$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "[INFO 24-04-15 13:46:00.8152 IST kernel.cc:825] Deployment config:\n",
      "cache_path: \"/tmp/tmp79khj61v/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO 24-04-15 13:46:00.8687 IST kernel.cc:887] Train model\n",
      "[INFO 24-04-15 13:46:00.8721 IST random_forest.cc:416] Training random forest on 6952 example(s) and 12 feature(s).\n",
      "[INFO 24-04-15 13:46:01.0280 IST random_forest.cc:802] Training of tree  1/300 (tree index:1) done accuracy:0.749017 logloss:9.04636\n",
      "[INFO 24-04-15 13:46:01.1151 IST random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.770812 logloss:4.2327\n",
      "[INFO 24-04-15 13:46:01.1596 IST random_forest.cc:802] Training of tree  21/300 (tree index:21) done accuracy:0.781789 logloss:2.75623\n",
      "[INFO 24-04-15 13:46:01.1903 IST random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.786105 logloss:2.20224\n",
      "[INFO 24-04-15 13:46:01.2321 IST random_forest.cc:802] Training of tree  41/300 (tree index:35) done accuracy:0.785385 logloss:1.89778\n",
      "[INFO 24-04-15 13:46:01.2734 IST random_forest.cc:802] Training of tree  52/300 (tree index:51) done accuracy:0.785385 logloss:1.76607\n",
      "[INFO 24-04-15 13:46:01.3127 IST random_forest.cc:802] Training of tree  62/300 (tree index:63) done accuracy:0.789413 logloss:1.5818\n",
      "[INFO 24-04-15 13:46:01.3544 IST random_forest.cc:802] Training of tree  72/300 (tree index:73) done accuracy:0.788119 logloss:1.46814\n",
      "[INFO 24-04-15 13:46:01.3947 IST random_forest.cc:802] Training of tree  83/300 (tree index:82) done accuracy:0.790852 logloss:1.38285\n",
      "[INFO 24-04-15 13:46:01.4350 IST random_forest.cc:802] Training of tree  94/300 (tree index:93) done accuracy:0.789125 logloss:1.32867\n",
      "[INFO 24-04-15 13:46:01.4772 IST random_forest.cc:802] Training of tree  104/300 (tree index:101) done accuracy:0.787975 logloss:1.24405\n",
      "[INFO 24-04-15 13:46:01.5276 IST random_forest.cc:802] Training of tree  114/300 (tree index:113) done accuracy:0.788694 logloss:1.20624\n",
      "[INFO 24-04-15 13:46:01.5621 IST random_forest.cc:802] Training of tree  124/300 (tree index:126) done accuracy:0.787975 logloss:1.18757\n",
      "[INFO 24-04-15 13:46:01.6021 IST random_forest.cc:802] Training of tree  134/300 (tree index:134) done accuracy:0.789845 logloss:1.17096\n",
      "[INFO 24-04-15 13:46:01.6390 IST random_forest.cc:802] Training of tree  144/300 (tree index:143) done accuracy:0.789989 logloss:1.13897\n",
      "[INFO 24-04-15 13:46:01.6909 IST random_forest.cc:802] Training of tree  154/300 (tree index:153) done accuracy:0.789125 logloss:1.10732\n",
      "[INFO 24-04-15 13:46:01.7215 IST random_forest.cc:802] Training of tree  164/300 (tree index:161) done accuracy:0.790564 logloss:1.08393\n",
      "[INFO 24-04-15 13:46:01.7624 IST random_forest.cc:802] Training of tree  174/300 (tree index:174) done accuracy:0.790132 logloss:1.06998\n",
      "[INFO 24-04-15 13:46:01.8017 IST random_forest.cc:802] Training of tree  184/300 (tree index:182) done accuracy:0.791427 logloss:1.0569\n",
      "[INFO 24-04-15 13:46:01.8450 IST random_forest.cc:802] Training of tree  194/300 (tree index:194) done accuracy:0.791283 logloss:1.02915\n",
      "[INFO 24-04-15 13:46:01.8957 IST random_forest.cc:802] Training of tree  204/300 (tree index:198) done accuracy:0.790708 logloss:1.0205\n",
      "[INFO 24-04-15 13:46:01.9325 IST random_forest.cc:802] Training of tree  214/300 (tree index:215) done accuracy:0.791715 logloss:0.993867\n",
      "[INFO 24-04-15 13:46:01.9767 IST random_forest.cc:802] Training of tree  224/300 (tree index:221) done accuracy:0.792146 logloss:0.984776\n",
      "[INFO 24-04-15 13:46:02.0200 IST random_forest.cc:802] Training of tree  234/300 (tree index:232) done accuracy:0.792865 logloss:0.97515\n",
      "[INFO 24-04-15 13:46:02.0559 IST random_forest.cc:802] Training of tree  244/300 (tree index:247) done accuracy:0.792002 logloss:0.969724\n",
      "[INFO 24-04-15 13:46:02.1001 IST random_forest.cc:802] Training of tree  254/300 (tree index:251) done accuracy:0.791715 logloss:0.941375\n",
      "[INFO 24-04-15 13:46:02.1371 IST random_forest.cc:802] Training of tree  264/300 (tree index:262) done accuracy:0.791571 logloss:0.927631\n",
      "[INFO 24-04-15 13:46:02.1824 IST random_forest.cc:802] Training of tree  275/300 (tree index:274) done accuracy:0.791427 logloss:0.918078\n",
      "[INFO 24-04-15 13:46:02.2269 IST random_forest.cc:802] Training of tree  285/300 (tree index:286) done accuracy:0.790564 logloss:0.905222\n",
      "[INFO 24-04-15 13:46:02.2759 IST random_forest.cc:802] Training of tree  295/300 (tree index:297) done accuracy:0.79042 logloss:0.904447\n",
      "[INFO 24-04-15 13:46:02.2917 IST random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.79042 logloss:0.904423\n",
      "[INFO 24-04-15 13:46:02.2922 IST random_forest.cc:882] Final OOB metrics: accuracy:0.79042 logloss:0.904423\n",
      "[INFO 24-04-15 13:46:02.6618 IST kernel.cc:919] Export model in log directory: /tmp/tmp79khj61v with prefix 279c318843444f8a\n",
      "[INFO 24-04-15 13:46:04.4272 IST kernel.cc:937] Save model in resources\n",
      "[INFO 24-04-15 13:46:30.9081 IST abstract_model.cc:881] Model self evaluation:\n",
      "Number of predictions (without weights): 6952\n",
      "Number of predictions (with weights): 6952\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.79042  CI95[W][0.782229 0.79843]\n",
      "LogLoss: : 0.904423\n",
      "ErrorRate: : 0.20958\n",
      "\n",
      "Default Accuracy: : 0.503021\n",
      "Default LogLoss: : 0.693129\n",
      "Default ErrorRate: : 0.496979\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "      1     2\n",
      "1  2749   748\n",
      "2   709  2746\n",
      "Total: 6952\n",
      "\n",
      "\n",
      "[INFO 24-04-15 13:46:34.8780 IST kernel.cc:1233] Loading model from path /tmp/tmp79khj61v/model/ with prefix 279c318843444f8a\n",
      "[INFO 24-04-15 13:46:35.9457 IST decision_forest.cc:734] Model loaded with 300 root(s), 216274 node(s), and 11 input feature(s).\n",
      "[INFO 24-04-15 13:46:35.9481 IST abstract_model.cc:1344] Engine \"RandomForestGeneric\" built\n",
      "[INFO 24-04-15 13:46:35.9482 IST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:48.038881\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7e95f35b36d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:21:34.611375Z",
     "start_time": "2024-04-15T08:18:13.707920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(metrics=[\"accuracy\"])\n",
    "evaluation = model.evaluate(test_ds, return_dict=True)\n",
    "print()\n",
    "\n",
    "for name, value in evaluation.items():\n",
    "    print(f\"{name}: {value:.4f}\")"
   ],
   "id": "beb5d16d2de09357",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 187s 89s/step - loss: 0.0000e+00 - accuracy: 0.7909\n",
      "\n",
      "loss: 0.0000\n",
      "accuracy: 0.7909\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:21:38.113533Z",
     "start_time": "2024-04-15T08:21:34.814102Z"
    }
   },
   "cell_type": "code",
   "source": "model.summary()",
   "id": "a6116983872f54cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"random_forest_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 1 (1.00 Byte)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 1 (1.00 Byte)\n",
      "_________________________________________________________________\n",
      "Type: \"RANDOM_FOREST\"\n",
      "Task: CLASSIFICATION\n",
      "Label: \"__LABEL\"\n",
      "\n",
      "Input Features (12):\n",
      "\tAge\n",
      "\tCabin\n",
      "\tCryoSleep\n",
      "\tDestination\n",
      "\tFoodCourt\n",
      "\tGroup\n",
      "\tHomePlanet\n",
      "\tRoomService\n",
      "\tShoppingMall\n",
      "\tSpa\n",
      "\tVIP\n",
      "\tVRDeck\n",
      "\n",
      "No weights\n",
      "\n",
      "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
      "    1.    \"CryoSleep\"  0.217632 ################\n",
      "    2.          \"Spa\"  0.214072 ###############\n",
      "    3.  \"RoomService\"  0.202774 ##############\n",
      "    4.       \"VRDeck\"  0.160245 #########\n",
      "    5.    \"FoodCourt\"  0.157805 ########\n",
      "    6. \"ShoppingMall\"  0.128001 #####\n",
      "    7.          \"Age\"  0.125791 #####\n",
      "    8.        \"Group\"  0.120335 ####\n",
      "    9.   \"HomePlanet\"  0.115114 ###\n",
      "   10.  \"Destination\"  0.097672 #\n",
      "   11.          \"VIP\"  0.082910 \n",
      "\n",
      "Variable Importance: NUM_AS_ROOT:\n",
      "    1.    \"CryoSleep\" 134.000000 ################\n",
      "    2.  \"RoomService\" 66.000000 #######\n",
      "    3.          \"Spa\" 53.000000 #####\n",
      "    4.       \"VRDeck\" 33.000000 ###\n",
      "    5. \"ShoppingMall\"  9.000000 \n",
      "    6.    \"FoodCourt\"  5.000000 \n",
      "\n",
      "Variable Importance: NUM_NODES:\n",
      "    1.          \"Age\" 32177.000000 ################\n",
      "    2.    \"FoodCourt\" 12857.000000 ######\n",
      "    3.          \"Spa\" 12432.000000 #####\n",
      "    4.       \"VRDeck\" 12200.000000 #####\n",
      "    5. \"ShoppingMall\" 11665.000000 #####\n",
      "    6.  \"RoomService\" 10453.000000 ####\n",
      "    7.  \"Destination\" 5529.000000 ##\n",
      "    8.        \"Group\" 4507.000000 #\n",
      "    9.   \"HomePlanet\" 3916.000000 #\n",
      "   10.    \"CryoSleep\" 1332.000000 \n",
      "   11.          \"VIP\" 919.000000 \n",
      "\n",
      "Variable Importance: SUM_SCORE:\n",
      "    1.    \"CryoSleep\" 149063.452929 ################\n",
      "    2.          \"Spa\" 132238.578397 ##############\n",
      "    3.  \"RoomService\" 112957.881648 ############\n",
      "    4.       \"VRDeck\" 112772.423362 ############\n",
      "    5.          \"Age\" 105156.567833 ###########\n",
      "    6.    \"FoodCourt\" 95888.716028 ##########\n",
      "    7.   \"HomePlanet\" 82220.178124 ########\n",
      "    8. \"ShoppingMall\" 66069.907436 ######\n",
      "    9.        \"Group\" 44918.760871 ####\n",
      "   10.  \"Destination\" 19812.036792 #\n",
      "   11.          \"VIP\" 3137.606830 \n",
      "\n",
      "\n",
      "\n",
      "Winner takes all: true\n",
      "Out-of-bag evaluation: accuracy:0.79042 logloss:0.904423\n",
      "Number of trees: 300\n",
      "Total number of nodes: 216274\n",
      "\n",
      "Number of nodes by tree:\n",
      "Count: 300 Average: 720.913 StdDev: 71.7626\n",
      "Min: 527 Max: 913 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 527, 546)  2   0.67%   0.67%\n",
      "[ 546, 565)  3   1.00%   1.67% #\n",
      "[ 565, 585)  2   0.67%   2.33%\n",
      "[ 585, 604) 11   3.67%   6.00% ###\n",
      "[ 604, 623) 16   5.33%  11.33% ####\n",
      "[ 623, 643) 14   4.67%  16.00% ###\n",
      "[ 643, 662) 15   5.00%  21.00% ####\n",
      "[ 662, 681) 18   6.00%  27.00% ####\n",
      "[ 681, 701) 32  10.67%  37.67% ########\n",
      "[ 701, 720) 31  10.33%  48.00% #######\n",
      "[ 720, 739) 20   6.67%  54.67% #####\n",
      "[ 739, 759) 42  14.00%  68.67% ##########\n",
      "[ 759, 778) 27   9.00%  77.67% ######\n",
      "[ 778, 797) 23   7.67%  85.33% #####\n",
      "[ 797, 817) 18   6.00%  91.33% ####\n",
      "[ 817, 836) 10   3.33%  94.67% ##\n",
      "[ 836, 855)  9   3.00%  97.67% ##\n",
      "[ 855, 875)  6   2.00%  99.67% #\n",
      "[ 875, 894)  0   0.00%  99.67%\n",
      "[ 894, 913]  1   0.33% 100.00%\n",
      "\n",
      "Depth by leafs:\n",
      "Count: 108287 Average: 11.4417 StdDev: 2.871\n",
      "Min: 2 Max: 15 Ignored: 0\n",
      "----------------------------------------------\n",
      "[  2,  3)     7   0.01%   0.01%\n",
      "[  3,  4)   217   0.20%   0.21%\n",
      "[  4,  5)   721   0.67%   0.87%\n",
      "[  5,  6)  1891   1.75%   2.62% #\n",
      "[  6,  7)  3519   3.25%   5.87% ##\n",
      "[  7,  8)  5503   5.08%  10.95% ###\n",
      "[  8,  9)  7515   6.94%  17.89% ####\n",
      "[  9, 10)  9089   8.39%  26.28% ####\n",
      "[ 10, 11) 10607   9.80%  36.08% #####\n",
      "[ 11, 12) 11534  10.65%  46.73% ######\n",
      "[ 12, 13) 12315  11.37%  58.10% ######\n",
      "[ 13, 14) 12426  11.48%  69.58% ######\n",
      "[ 14, 15) 11985  11.07%  80.65% ######\n",
      "[ 15, 15] 20958  19.35% 100.00% ##########\n",
      "\n",
      "Number of training obs by leaf:\n",
      "Count: 108287 Average: 19.2599 StdDev: 40.1454\n",
      "Min: 5 Max: 869 Ignored: 0\n",
      "----------------------------------------------\n",
      "[   5,  48) 99877  92.23%  92.23% ##########\n",
      "[  48,  91)  5043   4.66%  96.89% #\n",
      "[  91, 134)  1583   1.46%  98.35%\n",
      "[ 134, 178)   581   0.54%  98.89%\n",
      "[ 178, 221)   296   0.27%  99.16%\n",
      "[ 221, 264)   181   0.17%  99.33%\n",
      "[ 264, 307)   154   0.14%  99.47%\n",
      "[ 307, 351)   210   0.19%  99.67%\n",
      "[ 351, 394)   145   0.13%  99.80%\n",
      "[ 394, 437)    60   0.06%  99.86%\n",
      "[ 437, 480)    28   0.03%  99.88%\n",
      "[ 480, 524)    42   0.04%  99.92%\n",
      "[ 524, 567)    22   0.02%  99.94%\n",
      "[ 567, 610)    22   0.02%  99.96%\n",
      "[ 610, 653)     7   0.01%  99.97%\n",
      "[ 653, 697)    12   0.01%  99.98%\n",
      "[ 697, 740)     4   0.00%  99.98%\n",
      "[ 740, 783)     8   0.01%  99.99%\n",
      "[ 783, 826)     9   0.01% 100.00%\n",
      "[ 826, 869]     3   0.00% 100.00%\n",
      "\n",
      "Attribute in nodes:\n",
      "\t32177 : Age [NUMERICAL]\n",
      "\t12857 : FoodCourt [NUMERICAL]\n",
      "\t12432 : Spa [NUMERICAL]\n",
      "\t12200 : VRDeck [NUMERICAL]\n",
      "\t11665 : ShoppingMall [NUMERICAL]\n",
      "\t10453 : RoomService [NUMERICAL]\n",
      "\t5529 : Destination [NUMERICAL]\n",
      "\t4507 : Group [CATEGORICAL]\n",
      "\t3916 : HomePlanet [NUMERICAL]\n",
      "\t1332 : CryoSleep [NUMERICAL]\n",
      "\t919 : VIP [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 0:\n",
      "\t134 : CryoSleep [NUMERICAL]\n",
      "\t66 : RoomService [NUMERICAL]\n",
      "\t53 : Spa [NUMERICAL]\n",
      "\t33 : VRDeck [NUMERICAL]\n",
      "\t9 : ShoppingMall [NUMERICAL]\n",
      "\t5 : FoodCourt [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 1:\n",
      "\t227 : CryoSleep [NUMERICAL]\n",
      "\t183 : RoomService [NUMERICAL]\n",
      "\t146 : Spa [NUMERICAL]\n",
      "\t99 : FoodCourt [NUMERICAL]\n",
      "\t77 : VRDeck [NUMERICAL]\n",
      "\t67 : HomePlanet [NUMERICAL]\n",
      "\t38 : Group [CATEGORICAL]\n",
      "\t33 : ShoppingMall [NUMERICAL]\n",
      "\t16 : Age [NUMERICAL]\n",
      "\t14 : Destination [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 2:\n",
      "\t382 : Spa [NUMERICAL]\n",
      "\t330 : RoomService [NUMERICAL]\n",
      "\t288 : CryoSleep [NUMERICAL]\n",
      "\t255 : FoodCourt [NUMERICAL]\n",
      "\t211 : VRDeck [NUMERICAL]\n",
      "\t205 : HomePlanet [NUMERICAL]\n",
      "\t195 : Group [CATEGORICAL]\n",
      "\t120 : ShoppingMall [NUMERICAL]\n",
      "\t69 : Age [NUMERICAL]\n",
      "\t38 : Destination [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 3:\n",
      "\t744 : Spa [NUMERICAL]\n",
      "\t567 : FoodCourt [NUMERICAL]\n",
      "\t563 : VRDeck [NUMERICAL]\n",
      "\t555 : RoomService [NUMERICAL]\n",
      "\t485 : Group [CATEGORICAL]\n",
      "\t398 : HomePlanet [NUMERICAL]\n",
      "\t378 : CryoSleep [NUMERICAL]\n",
      "\t259 : ShoppingMall [NUMERICAL]\n",
      "\t192 : Age [NUMERICAL]\n",
      "\t114 : Destination [NUMERICAL]\n",
      "\t7 : VIP [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 5:\n",
      "\t2031 : Spa [NUMERICAL]\n",
      "\t1854 : VRDeck [NUMERICAL]\n",
      "\t1786 : FoodCourt [NUMERICAL]\n",
      "\t1509 : Group [CATEGORICAL]\n",
      "\t1410 : Age [NUMERICAL]\n",
      "\t1322 : RoomService [NUMERICAL]\n",
      "\t1106 : ShoppingMall [NUMERICAL]\n",
      "\t1040 : HomePlanet [NUMERICAL]\n",
      "\t582 : CryoSleep [NUMERICAL]\n",
      "\t513 : Destination [NUMERICAL]\n",
      "\t69 : VIP [NUMERICAL]\n",
      "\n",
      "Condition type in nodes:\n",
      "\t103480 : HigherCondition\n",
      "\t3728 : ContainsBitmapCondition\n",
      "\t779 : ContainsCondition\n",
      "Condition type in nodes with depth <= 0:\n",
      "\t300 : HigherCondition\n",
      "Condition type in nodes with depth <= 1:\n",
      "\t862 : HigherCondition\n",
      "\t38 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 2:\n",
      "\t1898 : HigherCondition\n",
      "\t193 : ContainsBitmapCondition\n",
      "\t2 : ContainsCondition\n",
      "Condition type in nodes with depth <= 3:\n",
      "\t3777 : HigherCondition\n",
      "\t470 : ContainsBitmapCondition\n",
      "\t15 : ContainsCondition\n",
      "Condition type in nodes with depth <= 5:\n",
      "\t11713 : HigherCondition\n",
      "\t1389 : ContainsBitmapCondition\n",
      "\t120 : ContainsCondition\n",
      "Node format: NOT_SET\n",
      "\n",
      "Training OOB:\n",
      "\ttrees: 1, Out-of-bag evaluation: accuracy:0.749017 logloss:9.04636\n",
      "\ttrees: 11, Out-of-bag evaluation: accuracy:0.770812 logloss:4.2327\n",
      "\ttrees: 21, Out-of-bag evaluation: accuracy:0.781789 logloss:2.75623\n",
      "\ttrees: 31, Out-of-bag evaluation: accuracy:0.786105 logloss:2.20224\n",
      "\ttrees: 41, Out-of-bag evaluation: accuracy:0.785385 logloss:1.89778\n",
      "\ttrees: 52, Out-of-bag evaluation: accuracy:0.785385 logloss:1.76607\n",
      "\ttrees: 62, Out-of-bag evaluation: accuracy:0.789413 logloss:1.5818\n",
      "\ttrees: 72, Out-of-bag evaluation: accuracy:0.788119 logloss:1.46814\n",
      "\ttrees: 83, Out-of-bag evaluation: accuracy:0.790852 logloss:1.38285\n",
      "\ttrees: 94, Out-of-bag evaluation: accuracy:0.789125 logloss:1.32867\n",
      "\ttrees: 104, Out-of-bag evaluation: accuracy:0.787975 logloss:1.24405\n",
      "\ttrees: 114, Out-of-bag evaluation: accuracy:0.788694 logloss:1.20624\n",
      "\ttrees: 124, Out-of-bag evaluation: accuracy:0.787975 logloss:1.18757\n",
      "\ttrees: 134, Out-of-bag evaluation: accuracy:0.789845 logloss:1.17096\n",
      "\ttrees: 144, Out-of-bag evaluation: accuracy:0.789989 logloss:1.13897\n",
      "\ttrees: 154, Out-of-bag evaluation: accuracy:0.789125 logloss:1.10732\n",
      "\ttrees: 164, Out-of-bag evaluation: accuracy:0.790564 logloss:1.08393\n",
      "\ttrees: 174, Out-of-bag evaluation: accuracy:0.790132 logloss:1.06998\n",
      "\ttrees: 184, Out-of-bag evaluation: accuracy:0.791427 logloss:1.0569\n",
      "\ttrees: 194, Out-of-bag evaluation: accuracy:0.791283 logloss:1.02915\n",
      "\ttrees: 204, Out-of-bag evaluation: accuracy:0.790708 logloss:1.0205\n",
      "\ttrees: 214, Out-of-bag evaluation: accuracy:0.791715 logloss:0.993867\n",
      "\ttrees: 224, Out-of-bag evaluation: accuracy:0.792146 logloss:0.984776\n",
      "\ttrees: 234, Out-of-bag evaluation: accuracy:0.792865 logloss:0.97515\n",
      "\ttrees: 244, Out-of-bag evaluation: accuracy:0.792002 logloss:0.969724\n",
      "\ttrees: 254, Out-of-bag evaluation: accuracy:0.791715 logloss:0.941375\n",
      "\ttrees: 264, Out-of-bag evaluation: accuracy:0.791571 logloss:0.927631\n",
      "\ttrees: 275, Out-of-bag evaluation: accuracy:0.791427 logloss:0.918078\n",
      "\ttrees: 285, Out-of-bag evaluation: accuracy:0.790564 logloss:0.905222\n",
      "\ttrees: 295, Out-of-bag evaluation: accuracy:0.79042 logloss:0.904447\n",
      "\ttrees: 300, Out-of-bag evaluation: accuracy:0.79042 logloss:0.904423\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:24:31.626186Z",
     "start_time": "2024-04-15T08:21:38.146095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test)\n",
    "\n",
    "submission_preds = model.predict(prediction_ds, verbose=2)"
   ],
   "id": "2b7353d716e86e26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 - 102s - 102s/epoch - 20s/step\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:24:31.792040Z",
     "start_time": "2024-04-15T08:24:31.668828Z"
    }
   },
   "cell_type": "code",
   "source": "submission_preds",
   "id": "5fc7f72aaf571560",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94333255],\n",
       "       [0.01333333],\n",
       "       [0.99999917],\n",
       "       ...,\n",
       "       [0.99666584],\n",
       "       [0.66666615],\n",
       "       [0.6699995 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:24:37.407556Z",
     "start_time": "2024-04-15T08:24:31.793527Z"
    }
   },
   "cell_type": "code",
   "source": "test_ids",
   "id": "70b2fff28281bb0e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0013_01\n",
       "1       0018_01\n",
       "2       0019_01\n",
       "3       0021_01\n",
       "4       0023_01\n",
       "         ...   \n",
       "4272    9266_02\n",
       "4273    9269_01\n",
       "4274    9271_01\n",
       "4275    9273_01\n",
       "4276    9277_01\n",
       "Name: PassengerId, Length: 4277, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:24:37.425569Z",
     "start_time": "2024-04-15T08:24:37.409170Z"
    }
   },
   "cell_type": "code",
   "source": "preds = [(i > 0.5)[0] for i in submission_preds]",
   "id": "c3688e369ab302f3",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:24:38.377090Z",
     "start_time": "2024-04-15T08:24:37.427186Z"
    }
   },
   "cell_type": "code",
   "source": "preds",
   "id": "f840e0f147cfe256",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:24:38.976576Z",
     "start_time": "2024-04-15T08:24:38.379290Z"
    }
   },
   "cell_type": "code",
   "source": "submission_df = pd.DataFrame({\"PassengerId\": test_ids, \"Transported\": preds})",
   "id": "91e39c9f9575e272",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:24:41.038920Z",
     "start_time": "2024-04-15T08:24:38.982447Z"
    }
   },
   "cell_type": "code",
   "source": "submission_df.to_csv(\"spaceship-titanic/submission.csv\", index=False)",
   "id": "5a49a2fcd7543faa",
   "outputs": [],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
